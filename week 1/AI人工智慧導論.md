---
tags: AI
---
# AI人工智慧導論

## ai數學基礎

### 學習路徑

- 入門基礎
    - 微積分
        - 極限，極值
    - 線性代數
        - 矩陣表示、特徵根、特徴向量
- 中級教程
    - 機率論、統計：統計概論、隨機過程
        - 隨機過程
            - 機率分佈是隨時間改變的
        - 馬可夫理論
            - 根據現在與過去的狀態進行預測，過去與現在式獨立的即是馬可夫性質（隨機過程）
            - MRP圖
            - ![](https://i.imgur.com/glKZc7s.png)

    - 線性規劃＋凸優化、非線性規劃
        - 分類分群
    - 數值計算、數值線代
        - 利用微分法求出近似解
- 高階教程
    - 深度學習
    - 強化學習
    - 機率圖
        - 機率
        - 貝式網路
        - 貝式信念網路

### 線性代數
1.標量、向量，矩陣和張量
- 標量（scalar) 一張標量就是一個單獨的數，用斜體表示標量，如s屬於r
- 向量（vector) 一個向量是一列數，我們用粗體的小寫名稱表示向量
- 張量（tensor) 某些情況下，我們會討論不只維座標的規則網路中，表示為$A_(ijk)$
- 轉置（transpose) 矩陣的轉置是以對角線為軸的鏡像，這條從左上道右上角的對角線為主對角線。將矩陣A的轉置表示為$A^t$
- RANK秩 係只期限性獨立的行向量或是線性獨立的列向量，也就是說，若矩陣的秩為2，期限性獨立的行與列皆為0，也就是說一矩陣之中行與列接只剩下兩個元素
- 線性獨立
- 逆矩陣
    - 非奇異矩陣
    - 可逆矩陣
    - 解法：
        - 伴隨矩陣
        - 高斯
- 範數
- 特徵向量、特徴對角化、正交矩陣
- 特徵分解
- 分解運算(Singilar Vector Decomposition SVD)
    - 文字
    - 分析
    - 範例

### 微積分、機率與統計
- 導數與梯度
    - 一階導數即是梯度
    - 二階導數hession
- 梯度下降法、最佳化、牛頓法
    - 牛頓法
        - 疊代求解

### 與AI的關係

1. 矩陣運算
2. 深度學習之捲機神經網路
3. 平行運算
4. 機器學習的數學基礎

## 介紹

### 人工智慧的傳統方法
- rule base 已經驗做判斷
- 找出所有可能性
    - 窮舉法
        - 窮舉不完怎麼辦
    - 窮舉＋智慧搜尋
        - 西洋棋

### 人工智慧應用

- 生物（人）的感知機制
- 影像偵測
- 自駕車

## 資源

[openai](https://openai.com/)
[人工智慧平台鴻海](https://ai.foxconn.com/textbook/interactive)

